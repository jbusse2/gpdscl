{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mm2ttl\n",
    "\n",
    "This file *mindmap to turtle (mm2ttl)* contains all functions to translate a gpdscl-annotated freeplane mindmap to OWL 2 in turtle format.\n",
    "\n",
    "\n",
    "* Johannes Busse, <http://www.jbusse.de/gpdscl>, email: jbusse at jbusse dot de\n",
    "* Version 0.24, 2021-01-19\n",
    "\n",
    "This early version of the documentation still contains text in DE. We ask for your understanding.\n",
    "\n",
    "\n",
    "\n",
    "jupytext: \n",
    "* pair with percent script to get a .py file which can be imported\n",
    "* pair with Myst-Markdown to write jupytext-docu in an external editor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "from xml.etree.ElementTree import Element, SubElement\n",
    "from datetime import datetime\n",
    "from xml.sax.saxutils import escape, unescape, quoteattr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "classificationAxioms = False\n",
    "restrictionSomeAxioms = False\n",
    "owl2punning = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Einführung (DE)\n",
    "\n",
    "\n",
    "\n",
    "GPDSCL:\n",
    "* Genus Proximus\n",
    "* Differentia Specifica\n",
    "* Clasification Language\n",
    "\n",
    "Mit der GPDSCL kann eine Klassifikation nach dem Modellierungs-Pattern [Genus proximum et differentia specifica](https://de.wikipedia.org/wiki/Genus_proximum_et_differentia_specifica) (a) anwenderfreundlich in einer Mindmap notiert und (b) in verschiedene Ontologiesprachen (insbesondere SKOS und OWL) übersetzt werden.\n",
    "\n",
    "GPDSCL ist eine domänenspezifische Sprache (DSL) und damit  eine \"höhere Sprache\", die \"die in Abstraktion und Komplexität von der Ebene der Maschinensprachen ... entfernt ist\" ([Wikipedia > Domänenspezifische Sprache](https://de.wikipedia.org/wiki/Dom%C3%A4nenspezifische_Sprache)).\n",
    "\n",
    "Notiert wird GPDSCL  im RDF-Datenmodell als [\"gestreifter\"](https://www.w3.org/2001/10/stripes/)  Baum, aus dem mittels eines Code-Generators eine OWL-Ontologie erzeugt werden kann.\n",
    "\n",
    "Für den Prototyp wählen wir folgende Technik:\n",
    "* Wir bauen den RDF-Graphen als Mindmap auf.\n",
    "* Für das Editieren der Mindmap verwenden wir die Open Source Software [ freeplane.org](https://www.freeplane.org/wiki/index.php/Home). Der Code-Generator dockt allerdings nicht an freeplane an, sondern wertet Dateien ausschließlich freeplane Datenformat `.mm` (ein XML-Format) aus. Damit kann jede andere Mindmap-Software verwendet werden, die das `.mm`-Format erzeugen kann.\n",
    "* Wir erzeugen OWL im Format Turtle.\n",
    "\n",
    "\n",
    "## basic utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_button_cancel(node):\n",
    "    return 'button_cancel' in [ icon.attrib['BUILTIN'] for icon in node.findall(\"icon\") ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeIri(text, startwith=0):\n",
    "    iri = escape(\"_\".join(text.split()[startwith:]))\n",
    "    if \":\" not in iri:\n",
    "        iri = \":\" + iri\n",
    "    return iri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeIriFromNode(node, startwith=0):\n",
    "    \n",
    "    if 'TEXT' in node.attrib:\n",
    "        myText = node.attrib['TEXT']\n",
    "    else:\n",
    "        myText = 'ERROR: NO_TEXT_ATTRIBUTE'\n",
    "    \n",
    "    if myText == '_':\n",
    "        myText = node.attrib['ID']\n",
    "        \n",
    "    #myText = node.attrib['TEXT'] if 'TEXT' in node.attrib else \"_\"\n",
    "    #print(f'TEXT={myText}')\n",
    "    #myText = node.attrib['ID'] if myText == '_' else myText\n",
    "    \n",
    "    myTextList = myText.split()\n",
    "    myTag = myTextList[0]\n",
    "    myIri = makeIri(myText, startwith) # escape(\"_\".join(myTextList[startwith:]))\n",
    "    return myTag, myIri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listOfValidChildren(node):\n",
    "    return [n for n in node.findall('node') if not(test_button_cancel(n))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listOfChildIris(node):\n",
    "    return [ makeIriFromNode(n, 0) for n in listOfValidChildren(node) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attachToNode(node, text, highlight):\n",
    "\n",
    "    \"\"\"add a text note to a mindmap node\"\"\"\n",
    "\n",
    "    [ node.remove(n) for n in node.findall('font') ]\n",
    "    node.attrib['BACKGROUND_COLOR'] = \"#ffffff\"\n",
    "    node.attrib['STYLE'] = \"fork\"\n",
    "    \n",
    "    if highlight == 'predicate':\n",
    "        ET.SubElement(node, 'font', {'ITALIC': 'true'})\n",
    "        \n",
    "    elif highlight == 'class':\n",
    "        ET.SubElement(node, 'font', {'BOLD': 'true'})\n",
    "        # node.attrib['STYLE'] = 'bubble'\n",
    "        \n",
    "    elif highlight == 'example':\n",
    "        node.attrib['STYLE'] = \"fork\"\n",
    "        # node.attrib['COLOR'] = \"#666666\"\n",
    "        \n",
    "    elif highlight == 'text':\n",
    "        node.attrib['COLOR'] = \"#666666\"\n",
    "        \n",
    "    elif highlight == 'WARNING':\n",
    "        node.attrib['BACKGROUND_COLOR'] = \"#ff0000\"\n",
    "        node.attrib['COLOR'] = \"#000000\"\n",
    "    \n",
    "    if node.find('richcontent') != None:\n",
    "        for r in node.findall('richcontent'):\n",
    "            node.remove(r)  \n",
    "    \n",
    "    richcontent = ET.SubElement(node, 'richcontent', attrib = {'TYPE': 'NOTE'})\n",
    "    html = ET.SubElement(richcontent, 'html')\n",
    "    body = ET.SubElement(html, 'body')\n",
    "    pre = ET.SubElement(body, 'pre')\n",
    "    pre.text = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verbose(node, text, verboseLevel):\n",
    "\n",
    "    \"\"\"print mindmap node ID and ISO version of timestamp\"\"\"\n",
    "    \n",
    "    verbosity = 2 # TBD: use class attribute etc.\n",
    "    ts = int(node.attrib['MODIFIED']) // 1000 \n",
    "    tsIso = datetime.utcfromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S')\n",
    "    nodeId = node.attrib['ID']\n",
    "    return f\"\\n# {text}        {nodeId} {tsIso}\\n\" if verboseLevel <= verbosity else \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WARNING(node, elementType, *, gp, dsa, dt):\n",
    "    # WARNING: \n",
    "    \n",
    "    owlCode =  f\"# T-box warning: unknown {elementType}: {node.get('TEXT')}\"\n",
    "    attachToNode(node, owlCode, 'WARNING')\n",
    "\n",
    "    for n in listOfValidChildren(node):        \n",
    "        searchForOntology(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WARNING2(node, elementType, *, gp, dsa, dt):\n",
    "    # WARNING: \n",
    "    \n",
    "    owlCode =  f\"# A-Box warning 2: unknown {elementType}: {node.get('TEXT')}\"\n",
    "    attachToNode(node, owlCode, 'WARNING')\n",
    "\n",
    "    for n in listOfValidChildren(node):        \n",
    "        searchForOntology(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ERROR(node, text):\n",
    "    print(makeIriFromNode, text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Depth first tree traversal\n",
    "\n",
    "Traverse the xml file of a freeplane mindmap in depth first order. If we find a node which stars with \"ONTOLOGY \" we start to interpret the subtree as a gpdscl annotated mindmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def searchForOntology(node):\n",
    "\n",
    "    \"\"\"walk mindmap, search for nodes with tag 'ONTOLOGY' \"\"\"\n",
    "    if test_button_cancel(node): return\n",
    "\n",
    "    myTag, myIri = makeIriFromNode(node, 1)\n",
    "    \n",
    "    if myTag == 'ONTOLOGY':\n",
    "        ONTOLOGY(node, 'predicate', gp=None, dsa=None, dt=None)\n",
    "    \n",
    "    else:\n",
    "        for n in node.findall(\"node\"):\n",
    "            searchForOntology(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The current node is a rdf resource. Starting from here we expect the child nodes being rdf predicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def walkPredicates(node, *, gp, dsa, dt):\n",
    "    \"\"\"walk mindmap, expect predicates\"\"\"\n",
    "    for n in listOfValidChildren(node):\n",
    "        myTag, myIri = makeIriFromNode(n, 1)\n",
    "        template = predicateTemplates.get(myTag, WARNING)\n",
    "        template(n, 'predicate', gp=gp, dsa=dsa, dt=dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The current node is a rdf resource. Starting from here we expect the child nodes being rdf predicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def walkPredicateInstances(node, *, s, p, o):\n",
    "    \"\"\"walk mindmap, expect predicate instances\"\"\"\n",
    "    for n in listOfValidChildren(node):\n",
    "        myTag, myIri = makeIriFromNode(n, 1)\n",
    "        template = predicateInstanceTemplates.get(myTag, WARNING2)\n",
    "        template(n, 'predicate', s=s, p=p, o=o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T-Box templates\n",
    "\n",
    "function parameter:\n",
    "\n",
    "* node ... an ElemTree XML node with the XML name \"node\"\n",
    "* element type: one of {'predicate', 'object'}\n",
    "* gp  ... genus proximum\n",
    "* dsa ... differentia specifica attribute\n",
    "* dt  ... definition term\n",
    "* dsv ... differentia specifica value\n",
    "\n",
    "\n",
    "(ontology)=\n",
    "### ONTOLOGY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ONTOLOGY(node, elementType, *, gp, dsa, dt):\n",
    "    if test_button_cancel(node): return\n",
    "\n",
    "    # ONTOLOGY source (predicate, new dsa)  # we are called here\n",
    "    #   milk (object)                       # and will also process these nodes\n",
    "    #     BY has_Source (predicate)         # we will call this level next \n",
    "    \n",
    "    myTag, myIri = makeIriFromNode(node, 1)\n",
    "\n",
    "    owlCode = verbose(node, \"ONTOLOGY, predicate\", 2)\n",
    "    owlCode += f\"\"\"\\n@prefix : <http://jbusse.de/ontology/mm2owl#> .\"\"\"\n",
    "    attachToNode(node, owlCode, 'predicate')\n",
    "        \n",
    "    for n in listOfValidChildren(node):\n",
    "        \n",
    "        _, myIri = makeIriFromNode(n, 0)\n",
    "        \n",
    "        owlCode = verbose(n, \"ONTOLOGY, object\", 2)\n",
    "        owlCode += f\"\"\"\\n{myIri} a owl:Class.\"\"\"\n",
    "        attachToNode(n, owlCode, 'class')\n",
    "        \n",
    "        walkPredicates(n, gp='OntologyTopConcept', dsa='OntologyTopProperty', dt=myIri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(by)=\n",
    "### BY\n",
    "\n",
    "    Milch\n",
    "      BY hat_Quelle\n",
    "        Kuhmilch\n",
    "        Ziegenmilch\n",
    "      BY hat_Verpachung\n",
    "        Flaschenmilch\n",
    "        Tetrapack-Milch\n",
    "\n",
    "Die SKOS-Semantik ist angelehnt an <https://www.w3.org/TR/skos-primer#seccollections>:\n",
    "\n",
    "    milk (skos:Concept)\n",
    "      <milk by source animal> (skos:Collection)\n",
    "        cow milk (skos:Concept)\n",
    "        goat milk (skos:Concept)\n",
    "        buffalo milk (skos:Concept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BY(node, elementType, *, gp, dsa, dt):\n",
    "    \"\"\"\n",
    "    BY: differentia specifica\n",
    "    #    liquid (object, gp)\n",
    "    #      ... (predicate, former dsa)\n",
    "    #        milk (object, dt)\n",
    "    #          BY source (predicate, new dsa)  # we are called here\n",
    "    #            cow milk (object)             # and will also process these nodes\n",
    "    \"\"\"\n",
    "    \n",
    "    myTag, myIri = makeIriFromNode(node, 1)\n",
    "    dsa = myIri if len(myIri) >0 else ':myTopObjectProperty'  # set dsa to new differentia specifica attribute\n",
    "\n",
    "    owlCode = verbose(node, \"BY, predicate\", 2)\n",
    "    owlCode += f\"\"\"\\n{dsa} a owl:ObjectProperty .\"\"\"\n",
    "    attachToNode(node, owlCode, 'predicate')\n",
    "\n",
    "    for n in listOfValidChildren(node):  \n",
    "        \n",
    "        if n.get('TEXT') != '_':\n",
    "            _, myIri = makeIriFromNode(n, 0)\n",
    "        else:\n",
    "            # generate a nice readable IRI\n",
    "            childIriSome = [ makeIriFromNode(child, 1)[1] \\\n",
    "                            for child in listOfValidChildren(n)\\\n",
    "                            if makeIriFromNode(child, 1)[0] == 'SOME']\n",
    "            print(childIriSome)\n",
    "            if len(childIriSome) > 0:\n",
    "                if childIriSome[0] != \"\":\n",
    "                    myIri = f\"{dt}_{dsa[1:]}_{childIriSome[0][1:]}\"\n",
    "                \n",
    "        owlCode = verbose(n, \"BY, object\", 2)\n",
    "        owlCode += f\"\"\"\\n{myIri} a owl:Class ;\n",
    "            rdfs:subClassOf {dt} .\"\"\"\n",
    "            \n",
    "        attachToNode(n, owlCode, 'class')\n",
    "        walkPredicates(n, gp=dt, dsa=dsa, dt=myIri)  # parameter shift here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(isa)=\n",
    "### ISA, Teilmenge\n",
    "\n",
    "    Tier\n",
    "      ISA\n",
    "        Kuh\n",
    "\n",
    "Semantik:\n",
    "* Jedes Ding, das Element der Menge *Kuh* ist, ist auch Element der Menge *Tier*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ISA(node, elementType, *, gp, dsa, dt):\n",
    "\n",
    "    \"\"\"\n",
    "    ISA: subclass\n",
    "    #    liquid (object, gp)\n",
    "    #      ... (predicate, former dsa)\n",
    "    #        milk (object, dt)\n",
    "    #          ISA                             # we are called here\n",
    "    #            cow milk (object)\n",
    "    \"\"\"\n",
    "    \n",
    "    # myTag, myIri = makeIriFromNode(node, 1)\n",
    "    # dsa = myIri if len(myIri) >0 else ':myTopObjectProperty'  # set dsa to new differentia specifica attribute\n",
    "\n",
    "    owlCode = verbose(node, \"ISA, predicate: nothing to do here\", 2)\n",
    "    attachToNode(node, owlCode, 'predicate')\n",
    "\n",
    "    for n in listOfValidChildren(node):        \n",
    "        _, myIri = makeIriFromNode(n, 0)\n",
    "            \n",
    "        owlCode = verbose(n, \"ISA, object\", 2)\n",
    "        owlCode += f\"\"\"\\n{myIri} a owl:Class ;\n",
    "            rdfs:subClassOf {dt} .\"\"\"\n",
    "            \n",
    "        attachToNode(n, owlCode, 'class')\n",
    "        walkPredicates(n, gp=dt, dsa=dsa, dt=myIri)  # parameter shift here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(some)=\n",
    "### SOME: OWL existential restriction ∃\n",
    "\n",
    "    Milch\n",
    "      BY hat_Quelle\n",
    "        Kuhmilch\n",
    "          SOME Kuh\n",
    "\n",
    "Dieses 4-Tupel lässt sich als Pattern verstehen für ein Inferencing in zwei Richtungen.\n",
    "\n",
    "(richtung1)=\n",
    "#### Richtung 1: single Subclass -> multiple Superclasses\n",
    "\n",
    "Inferencing:\n",
    "* Schließe von Subclass (hier: Kuhmilch) auf Superclasses (hier: Kuh,  ∃ hat_Quelle.Kuh )\n",
    "\n",
    "Gegeben: Von einem Ding sei bekannt:\n",
    "* Das Ding ist ein Element der Menge Kuhmilch.\n",
    "\n",
    "Dann sind das hinreichende Angaben, um mit obiger Notation zweierlei daraus schließen zu können:\n",
    "* Dieses Ding ist auch Element der Menge Milch.\n",
    "* Dieses Ding auch Element der Menge derjenigen Dinge, die - neben möglicherweise anderen Quellen- mindestens auch eine Kuh als Quelle haben.\n",
    "\n",
    "(\"Hinreichend\" sind die Angaben, weil allein sie ausreichend sind, diese zwei Schlüsse zu ziehen. Wir benötigen keine zusätzlichen notwendigen weitere Angaben.)\n",
    "\n",
    "ACHTUNG: Die Notation täuscht hier etwas: Durch den Baum wird suggeriert, dass die Baum-Node `SOME Kuh` (∃ hat_Quelle.Kuh) eine Subklasse von Kuhmilch ist. Das ist *nicht* gemeint.  Tatsächlich ist obige Notation eine verdichtete Baum-Notation, die man - bezogen auf Richtung 1 - auch so notieren könnte:\n",
    "\n",
    "    Milch\n",
    "      Kuhmilch\n",
    "    ∃ hat_Quelle.Kuh\n",
    "      Kuhmilch\n",
    "\n",
    "Wichtig zu sehen ist hier, dass hier kein AND oder Ähnliches vorliegt, sondern dass hier zwei separate Subclass-Aussagen modelliert werden, die ein Reasoner unabhängig voneinander ausführen kann: Wenn bekannt ist, dass ein Ding eine Kuhmilch ist, dass lassen sich auch beide Oberklassen (\"Es ist eine Milch!\"; \"Es kommt von der Kuh!\") ableiten.\n",
    "\n",
    "Von Protege exportiert nach OWL/RDF (<http://jbusse.de/ontology/Milch>):\n",
    "\n",
    "    <!-- http://jbusse.de/ontology/Milch#Kuhmilch -->\n",
    "    \n",
    "    <owl:Class rdf:about=\"http://jbusse.de/ontology/Milch#Kuhmilch\">\n",
    "        <rdfs:subClassOf rdf:resource=\"http://jbusse.de/ontology/Milch#Milch\"/>\n",
    "        <rdfs:subClassOf rdf:resource=\"http://jbusse.de/ontology/Milch#SOME_hat_Quelle_Kuh\"/>\n",
    "        <rdfs:comment>Milch, die von der Kuh kommt</rdfs:comment>\n",
    "    </owl:Class>\n",
    "\n",
    "\n",
    "    <!-- http://jbusse.de/ontology/Milch#SOME_hat_Quelle_Kuh -->\n",
    "\n",
    "    <owl:Class rdf:about=\"http://jbusse.de/ontology/Milch#SOME_hat_Quelle_Kuh\">\n",
    "        <owl:equivalentClass>\n",
    "            <owl:Restriction>\n",
    "                <owl:onProperty rdf:resource=\"http://jbusse.de/ontology/Milch#hat_Quelle\"/>\n",
    "                <owl:someValuesFrom rdf:resource=\"http://jbusse.de/ontology/Milch#Kuh\"/>\n",
    "            </owl:Restriction>\n",
    "        </owl:equivalentClass>\n",
    "        <rdfs:subClassOf rdf:resource=\"http://jbusse.de/ontology/Milch#RestrictionClasses\"/>\n",
    "        <rdfs:comment>Die Menge aller Dinge, die eine Kuh als Quelle haben</rdfs:comment>\n",
    "    </owl:Class>\n",
    "\n",
    "\n",
    "(richtung2)=\n",
    "#### Richtung 2: Superclass 1 AND ... Superclass n -> Subclass\n",
    "\n",
    "Inferencing:\n",
    "* Schließe aus einem AND von mehreren Superclasses (hier: Milch,  ∃ hat_Quelle.Kuh) auf eine gemeinsame Subclass (hier: Kuhmilch)\n",
    "\n",
    "Gegeben: Von einem Ding sei bekannt:\n",
    "* Das Ding ist Element der Menge Milch, und\n",
    "* das Ding ist Element der Menge derjenigen Dinge, die eine Kuh als Quelle haben.\n",
    "\n",
    "Dann *seien uns diese Information hinreichend* für den Schluss:\n",
    "* Dieses Ding ist ein Element der Menge Kuhmilch.\n",
    "\n",
    "In  DL:\n",
    "\n",
    "    Kuhmilch ⊇ AND_Class_Kuhmilch\n",
    "    AND_Class_Kuhmilch == Milch ∧ ∃ hat_Quelle.Kuh\n",
    "    \n",
    "in Mengenschreibweise:\n",
    "\n",
    "    Kuhmilch ⊇ {x | Milch(x) ∧ ∃y[hat_Quelle(x,y) ∧ Kuh(y)] }\n",
    "\n",
    "\n",
    "in First Order Logic (FOL): \n",
    "\n",
    "    ∀x[Kuhmilch(x) ← Milch(x) ∧ ∃y[hat_Quelle(x,y) ∧ Kuh(y)]\n",
    "\n",
    "Um Richtung 2 (also solch ein Superclass --> Subclass-Inferencing) in einer Mindmap darstellen zu können, wäre ein AND hilfreich. Wir benötigen es aber nicht unbedingt explizit, sondern bauen es implizit in unser Pfad-Pattern mit der hier angegebenen  Superclasses -> Subclass-Semantik ein.\n",
    "\n",
    "In OWL verwendet man hier eine `owl:intersectionOf`. \n",
    "\n",
    "\n",
    "    <!-- http://jbusse.de/ontology/Milch#AND_Class_Kuhmilch -->\n",
    "\n",
    "    <owl:Class rdf:about=\"http://jbusse.de/ontology/Milch#AND_Class_Kuhmilch\">\n",
    "        <owl:equivalentClass>\n",
    "            <owl:Class>\n",
    "                <owl:intersectionOf rdf:parseType=\"Collection\">\n",
    "                    <rdf:Description rdf:about=\"http://jbusse.de/ontology/Milch#Kuh\"/>\n",
    "                    <rdf:Description rdf:about=\"http://jbusse.de/ontology/Milch#SOME_hat_Quelle_Kuh\"/>\n",
    "                </owl:intersectionOf>\n",
    "            </owl:Class>\n",
    "        </owl:equivalentClass>\n",
    "        <rdfs:subClassOf rdf:resource=\"http://jbusse.de/ontology/Milch#AND_Classes\"/>\n",
    "    </owl:Class>\n",
    "\n",
    "\n",
    "(vgl. auch das strukturäquivalende Beispiel aus <https://www.w3.org/TR/owl-xmlsyntax/apd-example.html#subapd-eg41>): \"Without such a definition it is possible to know that white wines are wines and white, but not vice-versa. This is an important tool for categorizing individuals.\"\n",
    "\n",
    "\n",
    "Diskussion: Durch obige Formulierung *\"seien uns diese Information hinreichend\"* wollen wir (in Umkehrung von Richtung 1 (eine Subclass -> mehrere Superclasses) hier in Richtung 2 annehmen, dass die Klasse Kuhmilch durch die drei anderen Angaben im Pfad   `Milch, BY hat_Quelle, _ , SOME Kuh` hinreichend (d.h. vollständig, umfassend, ohne dass weitere notwendige Bedingungen gelten müssen) bestimmt ist.  \n",
    "\n",
    "Dies ist eine vergleichsweise starke Annahme, die in Protege extra modelliert werden muss (d.h. nicht automatisch angelegt wird, wenn man zu einer Klasse einer Restriction hinzufügt). In welchen Kontexten können wir diese Annahme unterstützen wollen, und wo stört uns solch eine Annahme eher?\n",
    "   * Um allgemeine OWL-Ontologien zu modellieren ist diese Annahme sicherlich zu stark.\n",
    "   * Um eine Mindmap-basierte Sprache zu definieren,  um gemäß dem *genus proximum, differentia specifica*-Pattern eine Facetten-Klassifikation zu notieren, dürfte diese Annahme ein ganz guter Kompromiss sein.\n",
    "   * Diskutieren: Wenn man erlaubt, dass dasselbe Konzept an verschiedenen Stellen der Ontologie stückweise defininiert wird:\n",
    "      * sind das dann verschiedene, alternative lokale Stories?\n",
    "      * oder sollten für das Richtung-2-Inferencing alle Konjunktionsglieder eingesammelt werden? Damit lässt sich das Richtung-2-Inferencing nicht mehr durch eine rein lokale Code-Generierung handhaben.\n",
    "\n",
    "#### Richtung 1 + Richtung 2\n",
    "\n",
    "\n",
    "Die hier angegebenen OWL/XML-Auszüge sind nicht falsch oder korrekt, sondern sie *definieren* die Semantik des bislang rein syntaktisch beschriebenen Teilpfades `... BY ... SOME ... `  einer Mindmap. \n",
    "\n",
    "Es stellen sich allerdings sofort  die folgenden Fragen:\n",
    "* Wären andere Definitionen sinnvoller?\n",
    "* Wollen wir OWL verwenden, oder \"reicht\" und RDF(S)?\n",
    "\n",
    "Die Antwort auf diese Fragen hängt davon ab, welches Inferencing wir im Kopf haben.\n",
    "\n",
    "In der hier vorgeschlagenen Semantik für einen Teilpfad der Form Pfad   `Milch, BY hat_Quelle, Kuhmilch, SOME Kuh` wird ein Inferncing ermöglicht, mit dem ein Ding anhand seiner charakteristischen Eigenschaften vom Allgemeinen immer spezieller zum Besonderen hin klassifiziert werden kann."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SOME(node, elementType, *, gp, dsa, dt):\n",
    "\n",
    "    \"\"\"\n",
    "    SOME\n",
    "    #    milk (object, gp)\n",
    "    #      BY has_Source (predicate, dsa)\n",
    "    #        cow milk (object, dt)         # we are called here\n",
    "    #          SOME cow  (predicate, dsv)\n",
    "    \"\"\"\n",
    "    myTag, myIri = makeIriFromNode(node, 1)\n",
    "    dsv = myIri  # differentia specifica value\n",
    "\n",
    "    # be careful: construct IRI without leading \":\", attach later\n",
    "    # eliminate \":\" from dsa and dsv\n",
    "    someClass = f\"SOME_{dsa[1:]}_IS_{dsv[1:]}\"  \n",
    "    # alternative: someClass = 'SOME_' + node.get('ID')  \n",
    "    \n",
    "    andClass  = f\"{gp}_AND_{someClass}\"  # IRI gets the leading \":\" from gp\n",
    "\n",
    "    owlCode = verbose(node, \"SOME, predicate\", 2)\n",
    "\n",
    "    if restrictionSomeAxioms:\n",
    "        owlCode += f\"\"\"\\n:{someClass} a owl:Class ;\n",
    "        owl:equivalentClass [ a owl:Restriction ;\n",
    "            owl:onProperty {dsa} ;\n",
    "            owl:someValuesFrom {dsv} ] .\"\"\"\n",
    "\n",
    "    if classificationAxioms:\n",
    "        owlCode += f\"\"\"\\n{andClass} a owl:Class ;\n",
    "        rdfs:subClassOf {dt} ;\n",
    "        owl:equivalentClass [ a owl:Class ;\n",
    "            owl:intersectionOf ( {gp} :{someClass} ) ] .\"\"\"\n",
    "\n",
    "    if owl2punning:\n",
    "        owlCode += f\"\"\"\\n# owl 2 punning\n",
    "        {dsv} a owl:Class ;\n",
    "            rdfs:subClassOf {dsa} .\n",
    "        \n",
    "        {dsv} rdf:type owl:NamedIndividual ;\n",
    "            a {dsv} .\"\"\"\n",
    "        \n",
    "    attachToNode(node, owlCode, 'predicate')       \n",
    "    \n",
    "    for n in listOfValidChildren(node):\n",
    "        \n",
    "        _, myIri = makeIriFromNode(n, 0)\n",
    "        \n",
    "        owlCode = verbose(n, \"SOME, object\", 2)\n",
    "        owlCode += f\"\"\"\\n{myIri} a owl:Class ;\n",
    "            rdfs:subClassOf {dt} .\"\"\"  \n",
    "        attachToNode(n, owlCode,'class')\n",
    "        \n",
    "        walkPredicates(n, gp=dt, dsa=dsa, dt=myIri)  # parameter shift here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(all)=\n",
    "### ALL: OWL for all restriction\n",
    "\n",
    "nicht implementiert\n",
    "\n",
    "(sup)=\n",
    "### SUP, Super-Set, Obermenge\n",
    "\n",
    "    Tier\n",
    "      ISA\n",
    "        Hengst\n",
    "          SUP\n",
    "\t    Maskulinum\n",
    "\t    Pferd\n",
    "\t    \n",
    "Semantik wie bei ISA, nur in die andere Richtung notiert: Tier ist eine Obermenge von Kuh. (Zugegeben, das erscheint ungewohnt. Aber das ist der Tribut dafür, dass wir mit Mindmaps und Bäumen arbeiten wollen statt mit Graph-Tools. )\n",
    "\n",
    "Mit SUP lässt  sich in einer Mindmap die \"untere Hälfte\", genauer: der poly-hierarchische Teil einer FCA in einer Mindmap notieren.\n",
    "\n",
    "Semantik Teil 1 (\"Richtung 1\"), Oder-Verknüpfung von ISA und SUP wie oben beschrieben:\n",
    "* *Hengst* ist Teilmenge von *Tier* (siehe oben, ISA)\n",
    "* *Hengst* ist Teilmenge von *Maskulinum* und *Pferd* (siehe oben, SUP)\n",
    "\n",
    "Semantik Teil 2 (\"Richtung 2\") - und wesentliche  Design-Entscheidung in GPDSCL:\n",
    "* Wenn wir von einem Ding wissen, dass es (a) ein Tier und (b) ein Maskulinum und ein Pferd ist\n",
    "* und wir diese Information in einer Ontologie in unmittelbarer Nachbarschaft als ein ISA - SUP Quintupel notieren\n",
    "* dann mögen uns diese Informationen genügen daraus zu schließen, dass dieses Ding ein Hengst ist.\n",
    "\n",
    "\n",
    " \n",
    "WICHTIG:\n",
    "* Die Kombination von ISA und SUP stellt in GPDSCL ein wesentliches Sprachelement dar, das die zunehmend genauere Klassierung von Beispielen anhand mehrerer Oberklassen ermöglicht.\n",
    "*  In [F-Logic](https://en.wikipedia.org/wiki/F-logic) würde man schreiben: `Hengst(X) <- Tier(X) AND Maskulinum(X) AND Pferd(X)`: *SUP ist gleichbedeutend mit konjunktiven Regeln.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SUP(node, elementType, *, gp, dsa, dt):\n",
    "\n",
    "    \"\"\"\n",
    "    SUP: Superclass. Similar to ISA, but reverse notation order in the mindmap\n",
    "    #    milk (gp)\n",
    "    #      BY something\n",
    "    #        bottled cow milk (object, dt) # superclass 1\n",
    "    #          SUP (predicate)     # we are called here\n",
    "    #            cow               # superclass 2\n",
    "    #            bottle            # superclass 3 etc.\n",
    "    \"\"\"\n",
    "    myTag, myIri = makeIriFromNode(node, 1)\n",
    "    dsv = myIri  # differentia specifica value\n",
    "    \n",
    "    SupClass = ':SUP_'+node.get('ID')\n",
    "    superclassIRIs = \" \".join([ makeIriFromNode(n,0)[1] \n",
    "                                     for n in listOfValidChildren(node) ])\n",
    "    owlCode = verbose(node, f\"SUP, predicate, gp=={gp}, dt=={dt}\", 2)        \n",
    "    owlCode += f\"\"\"\\n{SupClass} a owl:Class ;\n",
    "        rdfs:subClassOf {dt} ;\n",
    "        owl:equivalentClass [ a owl:Class ;\n",
    "            owl:intersectionOf \n",
    "                (  {superclassIRIs} ) ] .\"\"\"  # {gp}\n",
    "       \n",
    "    attachToNode(node, owlCode, 'predicate')       \n",
    "    \n",
    "    for n in listOfValidChildren(node):\n",
    "        _, myIri = makeIriFromNode(n, 0)\n",
    "        \n",
    "        owlCode = verbose(n, \"SUP, object\", 2)\n",
    "        owlCode += f\"\"\"\\n{dt} a owl:Class ;\n",
    "            rdfs:subClassOf {myIri} .\"\"\"  \n",
    "        \n",
    "        attachToNode(n, owlCode,'class')\n",
    "        walkPredicates(n, gp=':myTopObject', dsa=':myTopDataProperty', dt=myIri)  # parameter shift here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(ex)=\n",
    "### EX, Example\n",
    "\n",
    "    Kuh\n",
    "      EX\n",
    "        Elsa_12345\n",
    "            \n",
    "Semantik: \n",
    "* *Elsa_12345* ist ein Element der Menge *Kuh*.\n",
    "\n",
    "Beispiele von Beispielen sind in RDF übrigens perfekt möglich. In der Mathematik ist diese Idee trivialerweise als Potenzmenge bekannt. Problem: In Bezug auf Inferencing verlassen wir hier die First Order Logic, unser Inferencing wird unentscheidbar.\n",
    "\n",
    "    Boeing 747\n",
    "      EX\n",
    "        Air Force One\n",
    "          EX\n",
    "            VC-25A-33A275R3\n",
    "            \n",
    "RDFS-Interpretation: \n",
    "* Die *Air Force One* ist ein Element der Menge *Boeing 747*, und das Flugzeug mit der ID *VC-25A-33A275R3* ist ein Element der Menge *Air Force One*.\n",
    "\n",
    "In GPDSCL wollen wir keine Mengen von Mengen haben. Unklar, wie wir solche eine Modellierung übersetzen wollen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EX(node, elementType, *, gp, dsa, dt):\n",
    "\n",
    "    \"\"\"\n",
    "    EX: example, instance of\n",
    "    #        milk (object, dt)\n",
    "    #          EX (predicate, new dsa)  # we are called here\n",
    "    #            ID_123456 (example object)      # and will also process these nodes\n",
    "    \"\"\"\n",
    "    owlCode = verbose(node, \"EX, predicate\", 2)\n",
    "    attachToNode(node, owlCode,'predicate')\n",
    "        \n",
    "    for n in listOfValidChildren(node):        \n",
    "        _, myIri = makeIriFromNode(n, 0)\n",
    "\n",
    "        owlCode = verbose(n, \"EX, object\", 2)\n",
    "        owlCode += f\"\"\"\\n{myIri} a {dt} .\"\"\"\n",
    "        \n",
    "        attachToNode(n, owlCode, 'example')  \n",
    "        walkPredicateInstances(n, s=None, p=None, o=myIri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(ap)=\n",
    "### AP\n",
    "\n",
    "Annotation Property"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AP(node, elementType, *, gp, dsa, dt):\n",
    "\n",
    "    \"\"\"\n",
    "    AP: annotation property\n",
    "    #        milk (object, dt)\n",
    "    #          AP skos:definition (predicate, new )  # we are called here\n",
    "    #            some text# and will also process these nodes\n",
    "    \"\"\"\n",
    "    \n",
    "    myTag, myIri = makeIriFromNode(node, 1)\n",
    "    ap = myIri if myIri != ':' else 'rdfs:comment' \n",
    "\n",
    "    owlCode = verbose(node, \"AP, predicate\", 2)\n",
    "    owlCode += f\"\"\"\\n{ap} a owl:AnnotationProperty .\"\"\"\n",
    "    attachToNode(node, owlCode, 'predicate')\n",
    "\n",
    "    for n in listOfValidChildren(node):        \n",
    "        \n",
    "        owlCode = verbose(n, \"AP, literal\", 2)\n",
    "        owlCode = f\"\"\"\\n{dt} {ap} {quoteattr(node.attrib['TEXT'])} .\"\"\"\n",
    "        \n",
    "        attachToNode(n, owlCode, 'text')\n",
    "        \n",
    "        # do not walkPredicates(...): We are at a dead end here. \n",
    "        # instead search for ONTOLOGY:\n",
    "        \n",
    "        for n2 in listOfValidChildren(n):        \n",
    "            searchForOntology(n2)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used by function walkPredicates()\n",
    "predicateTemplates = {\n",
    "  'WARNING': WARNING,\n",
    "  'ONTOLOGY': ONTOLOGY,\n",
    "  'BY': BY, \n",
    "  'SOME': SOME,\n",
    "  'SUP': SUP,\n",
    "  'EX': EX,\n",
    "  'AP': AP,\n",
    "  'ISA': ISA,\n",
    " #'ASI': ASI ... use SUP instead\n",
    " }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A-Box templates\n",
    "\n",
    "(dp)=\n",
    "### DP\n",
    "\n",
    "Data Property"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DP(node, elementType, *, s, p, o):\n",
    "\n",
    "    \"\"\"DP: data property\n",
    "    #        milk (o object)\n",
    "    #          DP hat_Fettgehalt   # we are called here\n",
    "    #            1.5               # and will also process these nodes\n",
    "    \"\"\"\n",
    "    \n",
    "    myTag, myIri = makeIriFromNode(node, 1)\n",
    "    dp = myIri # TBD set default: if myIri != ':' else 'rdfs:comment' \n",
    "\n",
    "    owlCode = verbose(node, \"DP, predicate\", 2)\n",
    "    owlCode += f\"\"\"\\n{dp} a owl:DatatypeProperty .\"\"\"\n",
    "    attachToNode(node, owlCode, 'predicate')\n",
    "\n",
    "    for n in listOfValidChildren(node):\n",
    "        \n",
    "        owlCode = verbose(n, \"DP, literal\", 2)\n",
    "        owlCode = f\"\"\"\\n{o} {dp} {quoteattr(node.attrib['TEXT'])} .\"\"\"\n",
    "        \n",
    "        attachToNode(n, owlCode, 'text')\n",
    "        \n",
    "        # do not walkPredicates(...): We are at a dead end here. \n",
    "        # instead search for ONTOLOGY:\n",
    "        \n",
    "        for n2 in listOfValidChildren(n):        \n",
    "            searchForOntology(n2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(op)=\n",
    "### OP\n",
    "\n",
    "Object Property"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OP(node, elementType, *, s, p, o):\n",
    "\n",
    "    \"\"\"OP: object property\n",
    "    #        milk_1234 (o object)\n",
    "    #          OP hat_Hersteller   # we are called here\n",
    "    #            Weideglück        # and will also process these nodes\n",
    "    \"\"\"\n",
    "    \n",
    "    myTag, myIri = makeIriFromNode(node, 1)\n",
    "    op = myIri # TBD set default: if myIri != ':' else 'skos:narrower' \n",
    "\n",
    "    owlCode = verbose(node, \"OP, predicate\", 2)\n",
    "    owlCode += f\"\"\"\\n{op} a owl:ObjectProperty .\"\"\"\n",
    "    attachToNode(node, owlCode, 'predicate')\n",
    "\n",
    "    for n in listOfValidChildren(node):        \n",
    "        \n",
    "        _, childIri = makeIriFromNode(n, 0)\n",
    "    \n",
    "        owlCode = verbose(n, \"OP, literal\", 2)\n",
    "        owlCode = f\"\"\"\\n{o} {op} {childIri} .\"\"\"\n",
    "        \n",
    "        attachToNode(n, owlCode, 'text')\n",
    "        walkPredicateInstances(n, s=0, p=op, o=childIri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(xe)=\n",
    "### XE, elpmaxe\n",
    "\n",
    "EX (example), in umgekehrter Leserichtung geschrieben: EX, elpmaxe. Anwendung dort, wo ein Exemplar gleichzeitig als Element von mehreren Mengen gekennzeichnet werden soll.\n",
    "\n",
    "    Kuh\n",
    "      EX\n",
    "        Elsa_12345\n",
    "          XE\n",
    "            Femininum\n",
    "            Fleckvieh\n",
    "            \n",
    "Semantik: \n",
    "* *Elsa_12345* ist ein Element der Menge *Kuh* (aus EX)\n",
    "* *Elsa_12345* ist außerdem ein Element der Menge *Femininum* und der Menge *Fleckvieh* (aus XE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def XE(node, elementType, *, s, p, o):\n",
    "\n",
    "    \"\"\"XE: example, the other way round: the parent node is the example, the child nodes the respective classes.\n",
    "    #        ID_123456 (example object)\n",
    "    #          XE (predicate, new dsa)  # we are called here\n",
    "    #            milk (object, dt)      # and will also process these nodes\n",
    "    \"\"\"\n",
    "    attachToNode(node, '','predicate')\n",
    "        \n",
    "    for n in listOfValidChildren(node):        \n",
    "        _, myIri = makeIriFromNode(n, 0)\n",
    "        \n",
    "        owlCode = verbose(n, \"XE, object\", 2)\n",
    "        owlCode += f\"\"\"\\n{o} a {myIri} .\"\"\"\n",
    "        \n",
    "        attachToNode(n, owlCode, 'class')  \n",
    "        walkPredicates(n, gp=':myTopObject', dsa=':myTopObjectProperty', dt=':myTopObject')  # parameter shift here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used by walkPredicateInstances()\n",
    "predicateInstanceTemplates = {\n",
    "    'DP': DP,\n",
    "    'OP': OP,\n",
    "    'XE': XE\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate serialization\n",
    "\n",
    "Walk through the mindmap graph and collect all `richcontent[@TYPE=\"NOTE\"]/html/body/pre`-elements into the dict `owlEntries`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collectOwlEntries(owlEntries, node):\n",
    "    if test_button_cancel(node): return\n",
    "    pre = node.find('richcontent[@TYPE=\"NOTE\"]/html/body/pre')\n",
    "    if pre != None:\n",
    "        myId = node.attrib['ID']\n",
    "        owlEntries[myId] = pre.text\n",
    "        # print(\"collectOwlEntries:\", pre.text)\n",
    "    for n in node.findall('node'):\n",
    "        collectOwlEntries(owlEntries, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join the dict `owlEntries` to get a string version of the ontology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mm2turtle(node, baseUri, *, verbosity=0):\n",
    "    searchForOntology(node)\n",
    "    owlEntries = {}\n",
    "    collectOwlEntries(owlEntries, node)\n",
    "    joinedCollectedOwlEntries = \"\\n\".join(owlEntries.values())\n",
    "    ontologyString = f\"\"\"@prefix owl: <http://www.w3.org/2002/07/owl#> .\n",
    "@prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .\n",
    "@prefix xml: <http://www.w3.org/XML/1998/namespace> .\n",
    "@prefix xsd: <http://www.w3.org/2001/XMLSchema#> .\n",
    "@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .\n",
    "@prefix skos: <http://www.w3.org/2004/02/skos/core#> .\n",
    "\n",
    "@prefix : <{baseUri}#> .\n",
    "@base <{baseUri}> .\n",
    "<{baseUri}> rdf:type owl:Ontology .\n",
    "\n",
    "{joinedCollectedOwlEntries}\n",
    "    \"\"\"\n",
    "    print(f\"ontologyString: {ontologyString}\")\n",
    "    return ontologyString\n",
    "#    return owlEntries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "lines_to_next_cell": 3
   },
   "outputs": [],
   "source": [
    "#hookNode = root.find('.//node[hook]')\n",
    "#if hookNode:\n",
    "#    hook = hookNode.find('hook')\n",
    "#    hookNode.remove(hook)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,py:percent,md:myst"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
